# Step 1: Imports
import numpy as np, matplotlib.pyplot as plt, tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split

# Step 2: Dummy image & mask data
IMG_SIZE = 128
X = np.random.rand(100, IMG_SIZE, IMG_SIZE, 1).astype(np.float32)
y = np.random.randint(0, 2, (100, IMG_SIZE, IMG_SIZE, 1)).astype(np.float32)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)

# Step 3: Simple U-Net model
def unet(input_shape):
    i = layers.Input(input_shape)
    # Encoder
    e1 = layers.Conv2D(64, 3, activation='relu', padding='same')(i)
    e1 = layers.MaxPooling2D()(e1)
    e2 = layers.Conv2D(128, 3, activation='relu', padding='same')(e1)
    e2 = layers.MaxPooling2D()(e2)
    # Bottleneck
    b = layers.Conv2D(256, 3, activation='relu', padding='same')(e2)
    # Decoder
    d1 = layers.UpSampling2D()(b)
    d1 = layers.Conv2D(128, 3, activation='relu', padding='same')(d1)
    d2 = layers.UpSampling2D()(d1)
    d2 = layers.Conv2D(64, 3, activation='relu', padding='same')(d2)
    o = layers.Conv2D(1, 1, activation='sigmoid')(d2)
    return models.Model(inputs=i, outputs=o)

# Step 4: Compile & train
model = unet((IMG_SIZE, IMG_SIZE, 1))
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=5, batch_size=8)

# Step 5: Show sample prediction
pred = model.predict(X_val[0:1])[0].squeeze()
plt.subplot(1,3,1); plt.title("Input"); plt.imshow(X_val[0].squeeze(), cmap='gray')
plt.subplot(1,3,2); plt.title("Mask"); plt.imshow(y_val[0].squeeze(), cmap='gray')
plt.subplot(1,3,3); plt.title("Prediction"); plt.imshow(pred, cmap='gray')
plt.tight_layout(); plt.show()
